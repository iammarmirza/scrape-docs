---
title: Standalone Cluster
slug: installation-standalone-cluster
visibility: PUBLIC
label: Enterprise Server
ogImage: null
seoTitle: null
seoDescription: null
---
[Jump to Content](#content)

* * *

[System Status](https://deepsourcestatus.com/)[Community Forum](https://discuss.deepsource.com/)

Guides

[System Status](https://deepsourcestatus.com/)[Community Forum](https://discuss.deepsource.com/)

Standalone Cluster

Search

Standalone Cluster
==================

The standalone installation method is the quickest to install DeepSource Enterprise Server.

If you have the required permissions, you should be able to run your first analysis within 20 minutes. No prior knowledge of bootstrapping Kubernetes is required for this method as it has an embedded, production-ready Kubernetes distribution packaged with it.

> Note:
> 
> *   For pilot deployments, we recommend using a standalone cluster for a quick installation.
> *   Before you proceed with the installation, please make sure to go through the section of the documentation.

To install DeepSource Enterprise Server in the Standalone method, simply run the installation script in one of the nodes.

Shell

`curl -sSL https://kurl.sh/deepsource-fowl | sudo bash`

The above script will provision a Kubernetes cluster in the node and install the required services. This would take a few minutes.

You should be able to follow the on-screen instructions to port `8800` on your server to configure your instance, add additional nodes, check for updates, etc.

Joining Nodes

[](#joining-nodes)
-----------------------------------

Visit the admin console's **Cluster Management** tab to generate scripts for joining additional worker and master nodes.

For air-gapped installations, the airgap bundle must also be downloaded and extracted on the remote node prior to running the join script.

You should be able to follow the on-screen instructions to port `8800` on your server to configure your instance, add additional nodes, check for updates, etc.

Node Selectors

[](#node-selectors)
-------------------------------------

Node selector labels are to be set for segregating the application and analysis workloads. This is solely done to prevent resource starvation and/or performance degradation when the application traffic surges or the analysis workloads consume significant node resources. Before setting the node selector labels, it is required that the nodes have labels attached to them. To set the labels to the nodes, first run

Shell

`kubectl get nodes`

This will return the set of nodes managed by Kubernetes, as shown below

Shell

`NAME     STATUS   ROLES    AGE     VERSION node-1   Ready    master   6d14h   v1.16.4 node-2   Ready    <none>   6d14h   v1.16.4 node-3   Ready    <none>   6d14h   v1.16.4`

You can then set the labels for the nodes by running

Shell

`kubectl label nodes node-1 <your-desired-label>`

This will set the label for the node. You can set labels for other nodes as well. These labels should then be set in the admin console. For starters, set your 16 core machines (for application workloads) to one set of labels and your 10 core machines (for analysis workloads) to another set of labels. Kubernetes will deploy the pods to the appropriate node labels. For more information, refer to this [resource](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector).

Updated 6 months ago

* * *
